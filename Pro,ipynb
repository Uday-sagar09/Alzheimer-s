import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications import EfficientNetB3
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import cv2
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score
import seaborn as sns
import pandas as pd

# Paths
DATASET_DIR = "C:\\Users\\udayg\\OneDrive\\Desktop\\mini\\train"
MODEL_SAVE_DIR = "C:\\Users\\udayg\\OneDrive\\Desktop\\mini\\alzhemier\\models"
IMAGE_SIZE = (128, 128)
BATCH_SIZE = 32
EPOCHS = 50

# Data Preprocessing
datagen = ImageDataGenerator(rescale=1.0 / 255.0)

# Load the dataset and split it
data_flow = datagen.flow_from_directory(
    DATASET_DIR,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

file_paths = data_flow.filepaths
labels = data_flow.classes

# Print the number of unique classes in the dataset to check if it matches the defined classes
unique_classes = np.unique(labels)
print(f"Unique classes found in dataset: {unique_classes}")

# Define the class names manually
CLASSES = ['Mild Impairment', 'Moderate Impairment', 'No Impairment', 'Very Mild Impairment']
print(f"Updated CLASSES list: {CLASSES}")

# Split the dataset into train and test
train_paths, test_paths, train_labels, test_labels = train_test_split(
    file_paths, labels, test_size=0.2, stratify=labels, random_state=42
)

# Mapping the integer labels to class names dynamically
train_labels_str = [CLASSES[label] for label in train_labels]
test_labels_str = [CLASSES[label] for label in test_labels]

# Create DataFrames with file paths and class labels as strings
train_df = pd.DataFrame({"filename": train_paths, "class": train_labels_str})
test_df = pd.DataFrame({"filename": test_paths, "class": test_labels_str})

# Generators for training and testing
train_generator = datagen.flow_from_dataframe(
    train_df,
    x_col="filename",
    y_col="class",
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=True
)

test_generator = datagen.flow_from_dataframe(
    test_df,
    x_col="filename",
    y_col="class",
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

# Model Building
base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(128, 128, 3))
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu'),
    Dense(len(CLASSES), activation='softmax')
])

# Compile Model
model.compile(optimizer=Adam(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Train Model
history = model.fit(
    train_generator,
    epochs=EPOCHS,
    validation_data=test_generator  # Correct validation data
)

# Evaluate Model
test_loss, test_accuracy = model.evaluate(test_generator)
print(f"Test Accuracy: {test_accuracy}")

# Confusion Matrix and Classification Report
y_true = test_generator.classes
y_pred_probs = model.predict(test_generator)
y_pred_classes = np.argmax(y_pred_probs, axis=1)

print("Classification Report:")
print(classification_report(y_true, y_pred_classes, target_names=CLASSES))

balanced_accuracy = balanced_accuracy_score(y_true, y_pred_classes)
print(f"Balanced Accuracy: {balanced_accuracy}")

# Plot Confusion Matrix with Heatmap
def plot_confusion_matrix_with_heatmap(y_true, y_pred_classes, class_labels):
    cm = confusion_matrix(y_true, y_pred_classes)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title('Confusion Matrix Heatmap')
    plt.show()

plot_confusion_matrix_with_heatmap(y_true, y_pred_classes, CLASSES)

# Save Model
os.makedirs(MODEL_SAVE_DIR, exist_ok=True)
model.save(os.path.join(MODEL_SAVE_DIR, "efficientnetb3_classifier.h5"))
print(f"Model saved at: {MODEL_SAVE_DIR}/efficientnetb3_classifier.h5")

# Plot Training Curves
def plot_training_curves(history):
    plt.figure(figsize=(12, 6))

    # Accuracy Plot
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Accuracy Over Epochs')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    # Loss Plot
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Loss Over Epochs')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    plt.tight_layout()
    plt.show()

plot_training_curves(history)

# Grad-CAM Function
def grad_cam(input_model, image, class_index, layer_name="block7a_project_conv"):
    base_model = input_model.get_layer("efficientnetb3")
    if layer_name not in [layer.name for layer in base_model.layers]:
        raise ValueError(f"Layer '{layer_name}' not found in the base model. Please choose a valid layer.")
    grad_model = tf.keras.models.Model(
        inputs=base_model.input,
        outputs=[base_model.get_layer(layer_name).output, input_model.output]
    )
    with tf.GradientTape() as tape:
        inputs = tf.cast(image, tf.float32)
        tape.watch(inputs)
        conv_outputs, predictions = grad_model(inputs)
        loss = predictions[:, class_index]
    grads = tape.gradient(loss, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    conv_outputs = conv_outputs[0]
    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)
    heatmap = np.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
    return heatmap.numpy()

# Grad-CAM Visualization
def visualize_grad_cam(image_path, model, layer_name="block7a_project_conv"):
    img = tf.keras.utils.load_img(image_path, target_size=IMAGE_SIZE)
    img_array = tf.keras.utils.img_to_array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    predictions = model.predict(img_array)
    predicted_class = predictions.argmax()
    predicted_label = CLASSES[predicted_class]
    heatmap = grad_cam(model, img_array, predicted_class, layer_name)
    img = cv2.imread(image_path)
    img = cv2.resize(img, IMAGE_SIZE)
    heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))
    heatmap_resized = np.uint8(255 * heatmap_resized)
    heatmap_colored = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)
    superimposed_img = cv2.addWeighted(img, 0.6, heatmap_colored, 0.4, 0)
    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))
    plt.title(f"Predicted: {predicted_label}")
    plt.axis("off")
    plt.show()

# Example Grad-CAM Visualization
example_image_path = "C:\\Users\\udayg\\OneDrive\\Desktop\\mini\\train\\mild impairment\\MildImpairment (1).jpg"
visualize_grad_cam(example_image_path, model, layer_name="block7a_project_conv")
